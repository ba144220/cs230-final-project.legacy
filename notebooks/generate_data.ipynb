{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80b0b9d5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from transformers import AutoTokenizer, LlamaForCausalLM\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import glob\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# MODEL_NAME = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, token=os.getenv(\"HF_TOKEN\"))\n",
    "# model = LlamaForCausalLM.from_pretrained(MODEL_NAME, token=os.getenv(\"HF_TOKEN\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b57d14f9-7d54-4a9f-98bd-7e3f631280ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df: dataframe\n",
    "path: str path the store df\n",
    "\"\"\"\n",
    "def to_csv(df, path):\n",
    "    return df.to_csv(path)\n",
    "\n",
    "def to_html(df, path):\n",
    "    return df.to_html(path)\n",
    "\n",
    "def to_tsv(df, path):\n",
    "    return df.to_csv(path, sep='\\t')\n",
    "    \n",
    "\"\"\"\n",
    "df_type: data frame type to be returned any of (csv, html, tsv)\n",
    "task: QA task to be performed any of (arithmetic, item)\n",
    "row_size: row size of the dataset\n",
    "col_size: col size of the dataset\n",
    "file_name: name of file\n",
    "\"\"\"\n",
    "def generate_dataset(df_type, task, row_size, col_size, file_name):\n",
    "    columns = ['Col ' + str(i+1) for i in range(col_size)]\n",
    "    rows = ['Row ' + str(i+1) for i in range(row_size)]\n",
    "    if task == 'arithmetic': \n",
    "        df = pd.DataFrame(np.random.randint(1, 11, size=(row_size, col_size)), columns=columns, index=rows)\n",
    "    elif task == 'item':\n",
    "        df = pd.DataFrame(np.random.choice(list(string.ascii_uppercase), size=(row_size, col_size)), columns=columns, index=rows)\n",
    "    df_type_dict = {'csv': to_csv, 'html': to_html, 'tsv': to_tsv}\n",
    "    path = '../datasets/tables/' + file_name + '.' + df_type \n",
    "    return df_type_dict[df_type](df, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d9cbb7-0188-4b97-81ec-eb37c621a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = [4,6,8,10,12]\n",
    "\n",
    "for n in N:\n",
    "    generate_dataset('tsv', 'arithmetic', n, n, 'arithmetic_'+str(n))\n",
    "    generate_dataset('csv', 'arithmetic', n, n, 'arithmetic_'+str(n))\n",
    "    generate_dataset('html', 'arithmetic', n, n, 'arithmetic_'+str(n))\n",
    "\n",
    "    generate_dataset('tsv', 'item', n, n, 'item_'+str(n))\n",
    "    generate_dataset('csv', 'item', n, n, 'item_'+str(n))\n",
    "    generate_dataset('html', 'item', n, n, 'item_'+str(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a091357-e480-48cd-aeb3-5c3299b35e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../datasets/tables/*'\n",
    "file_paths = glob.glob(path)\n",
    "\n",
    "\"\"\"\n",
    "A qa.csv file contain all the questions and their corresponding context and answer\n",
    "question: str\n",
    "answer: str\n",
    "context: str (only the name of the table)\n",
    "id: unique str\n",
    "task: optional enum (“arithmetic” and “list-item”)\n",
    "direction: optional enum (“row” or “col”)\n",
    "size: optional tuple[int] \n",
    "\"\"\"\n",
    "def get_question():\n",
    "    #TODO\n",
    "    return \"\"\n",
    "\n",
    "def get_answer():\n",
    "    #TODO\n",
    "    return \"\"\n",
    "\n",
    "def get_context(file_path):\n",
    "    idx = file_path.find('tables')\n",
    "    return file_path[idx:]\n",
    "\n",
    "def get_id(i):\n",
    "    return \"nt-\" + str(i)\n",
    "\n",
    "def get_task(df):\n",
    "    #TOOD\n",
    "    series = df.apply(lambda s: pd.to_numeric(s, errors='coerce').notnull().all())[1:]\n",
    "    if (series.all()):\n",
    "        return 'arithmetic'\n",
    "    return 'item'\n",
    "\n",
    "def get_direction():\n",
    "    #TODO\n",
    "    return \"\"\n",
    "\n",
    "def get_size(df):\n",
    "    reshaped = (df.shape[0], df.shape[1]-1)\n",
    "    return str(reshaped)\n",
    "\n",
    "def read_html():\n",
    "    #TOOD\n",
    "    return\n",
    "    \n",
    "def tables_to_dataset():\n",
    "    dataset_df = pd.DataFrame(columns=['question', 'answer', 'context', 'id', 'task', 'direction', 'size'])\n",
    "    for i in range(len(file_paths)):\n",
    "        file_path = file_paths[i]\n",
    "        if (file_path.endswith('.csv')):\n",
    "            df = pd.read_csv(file_path)\n",
    "        elif (file_path.endswith('.tsv')):\n",
    "            df = pd.read_csv(file_path, sep='\\t')\n",
    "        elif (file_path.endswith('.html')):\n",
    "            #TODO\n",
    "            pass\n",
    "        file_name = file_path.split('/')[-1]\n",
    "        dataset_df.loc[i] = [get_question(), get_answer(), get_context(file_path), get_id(i), get_task(df), get_direction(), get_size(df)]\n",
    "    dataset_path = '../datasets/self_generated_qa.csv'\n",
    "    return dataset_df.to_csv(dataset_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dde1b786-9dd0-4207-8723-b823ff7d2f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIKI table example\n",
    "# TODO: .examples?\n",
    "wiki_path = '../datasets/data/*.tsv'\n",
    "wiki_file_paths = glob.glob(wiki_path)\n",
    "\n",
    "def wiki_tables_to_dataset():\n",
    "    dataset_df = pd.DataFrame(columns=['question', 'answer', 'context', 'id', 'task', 'direction', 'size'])\n",
    "    for i in range(len(wiki_file_paths)):\n",
    "        file_path = wiki_file_paths[i]\n",
    "        df = pd.read_csv(file_path, sep='\\t', on_bad_lines='skip')\n",
    "        dataset_df['question'] = df['utterance']\n",
    "        dataset_df['answer'] = df['targetValue']\n",
    "        dataset_df['context'] = df['context']#.apply(lambda x: x.split('/'[-1:]))\n",
    "        dataset_df['id'] = df['id']\n",
    "    dataset_path = '../datasets/wiki_qa.csv'\n",
    "    return dataset_df.to_csv(dataset_path, index=False)\n",
    "\n",
    "\n",
    "def merge_tables_and_wiki_tables():\n",
    "    dataset_path = '../datasets/qa.csv'\n",
    "    self_generated_path = '../datasets/self_generated_qa.csv'\n",
    "    wiki_dataset_path = \"../datasets/wiki_qa.csv\"\n",
    "    df =  pd.read_csv(self_generated_path)\n",
    "    wiki_df =  pd.read_csv(wiki_dataset_path)\n",
    "    merged_df = pd.concat([df, wiki_df], ignore_index=True)\n",
    "    return merged_df.to_csv(dataset_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c9b79fd-07d9-48c4-994b-1556c50c95cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_to_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5e9c869-aa33-4de5-8268-8e795378b919",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_tables_to_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2887065f-951c-4e24-851d-1d000c819430",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_tables_and_wiki_tables()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
